# CountVectorizer Comparison Project

Проект для сравнения различных методов предобработки текста при использовании CountVectorizer в машинном обучении.

## Описание проекта

Этот проект сравнивает 5 различных подходов к векторизации текста с использованием `CountVectorizer` из библиотеки scikit-learn:
1. **Базовый метод** - стандартный CountVectorizer без дополнительной обработки
2. **С удалением стоп-слов** - удаление общеупотребительных слов (например, "the", "and", "is")
3. **С лемматизацией** - приведение слов к их нормальной форме (лемме)
4. **Со стеммингом** - обрезание окончаний слов до основы (стема)
5. **С простым токенизатором** - быстрое разделение по пробелам без обработки пунктуации

Проект использует датасет новостей BBC для классификации и сравнивает эффективность каждого метода по нескольким метрикам.

## Быстрый старт

### Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/IlyaShaposhnikov/count-vectorizer.git
cd count-vectorizer
```

2. Установите зависимости:

```bash
pip install -r requirements.txt
```

3. [Скачайте датасет](https://www.kaggle.com/datasets/abdulraffayali/bbc-text-cls) и поместите его в папку `data` в корне проекта:

### Использование
Запустите основной скрипт сравнения:

```bash
python main.py
```

Скрипт автоматически:
1. Загрузит необходимые ресурсы NLTK (_При первом запуске это может занять несколько минут в зависимости от скорости вашего интернет-соединения. Последующие запуски будут происходить мгновенно._) 
2. Загрузит и подготовит данные
3. Обучит модели с разными методами векторизации
4. Выведет сравнение результатов
5. Создаст визуализации

## Структура проекта
```text
count-vectorizer/
├── data/                               # Папка с данными
│   └── bbc_text_cls.csv                # Датасет новостей BBC
├── methods/                            # Реализации различных методов векторизации
│   ├── base_vectorizer.py              # Базовый метод
│   ├── stopwords_vectorizer.py         # С удалением стоп-слов
│   ├── lemmatization_vectorizer.py     # С лемматизацией
│   ├── stemming_vectorizer.py          # Со стеммингом
│   └── simple_tokenizer_vectorizer.py  # С простым токенизатором
├── utils/                              # Вспомогательные утилиты
│   └── nltk_utils.py                   # Утилиты для работы с NLTK
├── results/                            # Папка для сохранения результатов
├── main.py                             # Основной скрипт сравнения
├── requirements.txt                    # Зависимости проекта
└── README.md                           # Этот файл
```

## Метрики сравнения
Каждый метод оценивается по следующим метрикам:
* Точность на тренировочных данных - точность модели на данных, на которых она обучалась
* Точность на тестовых данных - точность модели на новых данных (основная метрика)
* Размер словаря - количество уникальных слов после обработки
* Плотность матрицы - процент ненулевых элементов в матрице признаков
* Время выполнения - общее время обучения и оценки метода

## Технические детали
### Используемые библиотеки
* numpy - работа с числовыми массивами
* pandas - обработка и анализ данных
* scikit-learn - машинное обучение и CountVectorizer
* nltk - обработка естественного языка
* matplotlib/seaborn - визуализация результатов
* tabulate - человекочитаемое отображение таблиц

### Датасет
Проект использует датасет BBC News, содержащий 2225 документов в 5 категориях:
* business (510 документов)
* entertainment (386 документов)
* politics (417 документов)
* sport (511 документов)
* tech (401 документ)

### Алгоритм классификации
Для всех методов используется Multinomial Naive Bayes - алгоритм, хорошо зарекомендовавший себя для классификации текстов.

## Пример вывода
После запуска `main.py` вы увидите:
1. Прогресс выполнения каждого метода
2. Детальную таблицу сравнения
3. Графики с визуализацией результатов
4. Сохраненные результаты: таблица `detailed_results.csv` и график `comparison_results.png` в папке `results/`

## Ключевые выводы
Из сравнения обычно следует:
1. Удаление стоп-слов уменьшает размерность и часто улучшает качество
2. Лемматизация дает более качественные результаты, чем стемминг (97.31% против 96.77%)
3. Простые методы быстрее, но могут быть менее точными
4. Размер словаря напрямую влияет на время обучения модели
5. Плотность матрицы признаков обычно очень низкая (часто <1%, но может возрастать при агрессивной обработке текста, такой как стемминг или лемматизация, которые сокращают словарь)
6. Компромисс между скоростью и точностью: На датасете BBC News метод с удалением стоп-слов показал наилучший баланс, обеспечив максимальную точность (97.49%) при самом низком времени выполнения (0.46 с). Лемматизация дала схожую точность (97.31%), но оказалась значительно медленнее (33.66 с) из-за сложности лингвистического анализа.

## Автор
Илья Шапошников

https://github.com/IlyaShaposhnikov/

ilia.a.shaposhnikov@gmail.com
